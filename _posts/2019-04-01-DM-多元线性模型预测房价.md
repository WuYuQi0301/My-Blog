---
title: DM 多元线性模型预测房价
date: 2019-04-01 23:08:00
categories:
- Data Mining
tag
- dm-lab
---



双鸭山职业技术学校的附近的房价如何捏——买不起



梯度下降法GD
$$
\begin{align}\tau = 0:conv&ergence\\
\theta^{\tau+1}& = \theta^\tau-\rho(\tau)\triangledown logL(\theta^\tau|D)\\
&=\theta^\tau+\rho(\tau)\frac{1}{n}\sum^{n}_{i=1}(y_i-\theta^{(\tau)T}x_i)x_i
\end{align}
$$

随机梯度下降法SGD





### Ex.1

- 三个参数abc：$h(x) = ax_1+bx_2+c$，其中$h$为房子总价，$x_1$为房子面积，$x_2$为距离

- 第一次运行：

  ![1.1](C:\Users\Yuki\Desktop\2\1.1.JPG)

  ![Figure_1-1](..\pics\Figure_1-1.png)

- 由于第一次运行后可以看到算法在第20000次迭代附近就几乎无变化了。采样间隔过大不能直观地观察预测性能变化。于是将间隔缩小为100，并增加收敛条件（相邻两次迭代中三个参数的增量的平方和小于某个小量$e= 1e-8 $）即停止迭代：可见总体误差快速下降，迭代221755次（满足收敛条件）时只有参数c（bias）与最后结果误差较大，可见之后非常长的计算时间里都是在微调；

  ![1.2](C:\Users\Yuki\Desktop\2\1.2.JPG)

  ![Figure_1-2](C:\Users\Yuki\Desktop\2\Figure_1-2.png)

  

### Ex.2

- 学习率变为0.0002后，运行时警告溢出，参数结果为nan。

- 解决方法:标准化数据。结果是能够收敛了

![2.1](C:\Users\Yuki\Desktop\2\2.1.JPG)

![Figure_2-1](C:\Users\Yuki\Desktop\2\Figure_2-1.png)

### Ex.3

- SGD的计算速度非常快，10s左右可以完成同样次数的迭代。由于比较容易受噪声影响（下降方向可能是噪声方向），参数及会在真值附近微小的范围内震荡。


![3.1](C:\Users\Yuki\Desktop\2\3.1.JPG)

![Figure_3-1](C:\Users\Yuki\Desktop\2\Figure_3-1.png)

同样做数据标准化处理的结果：

![3.2](C:\Users\Yuki\Desktop\2\3.2.JPG)

![Figure_3-2](C:\Users\Yuki\Desktop\2\Figure_3-2.png)

### Source Code

```python
import numpy as np
import matplotlib.pyplot as plt
from random import random
import time

def hypothesis(a,b,c,x1,x2):
	return a * x1 + b * x2 + c

def display(step, err_train, err_test):
	plt.figure(1)
	plt.plot(step,err_train, color='blue', label="training error")
	plt.plot(step,err_test, color='red', label="testing  error")
	plt.show()

def normalization(dataset):
	mean = np.mean(dataset)
	var = np.var(dataset)
	return np.array([(data-mean)/var for data in dataset])

def read_dataset(path,N):
	price = np.zeros(N)
	area = np.zeros(N)
	distance = np.zeros(N)

	with open(path, 'r') as f:
		i = 0
		for line in f.readlines():
			cha = line.strip('\n').split(' ')
			area[i] = float(cha[0])
			distance[i] = float(cha[1])
			price[i] = float(cha[2])
			i += 1
	price = normalization(price)
	distance = normalization(distance)
	area = normalization(area)
	return [price, area, distance]

#read in data and normalization
N = 50
test_N = 10
[price, area, distance]  = read_dataset("dataForTraining.txt", N)
[test_price, test_area, test_distance] = read_dataset("dataForTesting.txt",test_N)


# init
iter_times = 1500000
# lr = 1.5e-4
lr = 0.0002
interval = 100000

# GD
# interval = 100
e = 1e-8

a = 0.0
b = 0.0
c = 0.0

step = []
err_train = []
err_test = []
time_start = time.time()

for i in range(iter_times):
	delta = [hypothesis(a,b,c,area[j],distance[j])-price[j] for j in range(N)]
	a_ = a - lr * np.mean(delta*area)
	b_ = b - lr * np.mean(delta*distance)
	c_ = c - lr * np.mean(delta)

	if i%interval == 0:
		step.append(i)
		err_train.append(np.mean([pow((hypothesis(a_,b_,c_,area[j],distance[j])-price[j]),2) for j in range(N)]))
		err_test.append(np.mean([pow((hypothesis(a_,b_,c_,test_area[j],test_distance[j])-test_price[j]),2) for j in range(test_N)]))

	# if (pow(a-a_, 2)+pow(b-b_,2))+pow(c-c_,2) < e:   #converge
	# 	a = a_
	# 	b = b_
	# 	c = c_
	# 	break

	a = a_
	b = b_
	c = c_

time_end = time.time() 

print("GD: Convergence times : %d"%(i))
print("final parameter : a = %f, b = %f, c = %f"%(a,b,c))
print("time cost : %f"%(time_end - time_start))
display(step, err_train, err_test)



#SGD

step = []
err_train = []
err_test = []

# iter_times = 20000
interval = 1000
lr = 0.00015
e = 1e-8

a = 0.0
b = 0.0
c = 0.0

time_start = time.time()
for i in range(iter_times):
	k = int(random()*N)
	a_ = a - lr * (hypothesis(a,b,c,area[k],distance[k])-price[k])*area[k]
	b_ = b - lr * (hypothesis(a,b,c,area[k],distance[k])-price[k])*distance[k]
	c_ = c - lr * (hypothesis(a,b,c,area[k],distance[k])-price[k])

	if i%interval == 0:
		step.append(i)
		err_train.append(np.mean([pow((hypothesis(a_,b_,c_,area[j],distance[j])-price[j]),2) for j in range(N)]))
		err_test.append(np.mean([pow((hypothesis(a_,b_,c_,test_area[j],test_distance[j])-test_price[j]),2) for j in range(test_N)]))

	a = a_
	b = b_
	c = c_

time_end = time.time()

print("SGD : times : %d"%(i))
print("final parameter : a = %f, b = %f, c = %f"%(a,b,c))
print("time cost : %f"%(time_end - time_start))
display(step, err_train, err_test)

```