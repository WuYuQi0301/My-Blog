---
title: ORB-SLAM论文摘要
date: 2019-04-02 15:00:00
categories:
- SLAM
tag:
- orb-slam

mathjax: true
---





*ORB-SLAM: a Versatile and Accurate Monocular SLAM System* 最初于2015.10发表在 IEEE Transactions on Robotics上，介绍了基于特征点法的经典系统 ORB-SLAM。



src: [ORB-SLAM: a Versatile and Accurate Monocular SLAM System](https://ieeexplore.ieee.org/document/7219438)



重要概念

- Covisibility Graph
- Essential Graph



## 简介

一个实时SLAM算法的BA应该有如下要求

1. 在候选图像帧子集（关键帧集）中，匹配观测的场景特征（地图云点）。
2. 因为计算复杂度随着关键帧的数量的增长而增长，需要筛选关键帧，避免冗余；
3. 关键帧和云点的的强网络结构能够有较为精确的结果，关键帧在观察点的时候能够有显著的视差（parallax）和足够的回环匹配（loop closure matches）
4. 对于关键帧和云点文职的初始估计，采用非线性优化
5. （探索）局部地图（优化的关键是获得良好的稳定性）
6. 实时执行快速全局优化（如pose graph）闭环回路



单目ORB-SLAM系统的主要技术及组件

1. 对所有任务（跟踪，建图，重定位，回环检测）使用相同的特征：ORB特征，具有旋转不变性，在无GPU下得到较好的实时性能。
2. 实时户外环境中的操作。由于使用了**covisibility graph**（视图内容关联？），跟踪和建图都关注一个局部covisible（视图关联）区域，可以独立于全局地图进行操作。
3. 基于位姿图优化的实时loop closing：*Essential Graph*。由生成树构建，生成树由系统、闭环控制链和来自covisibility graph的强边缘维护（It is built from a spanning tree maintained by the system, loop closure links, and strong edges from the covisibility graph）
4. 实时相机重定位具有旋转不变性，视角不变性和光度不变性，使得系统能够从跟踪失败中恢复，也能增强地图重用。
5. 基于不同的模型选择，会有不同的初始化过程，能够创建不同二维和非二维场景的初始地图，也是自动且具有良好鲁棒性的。
6. 用于地图云点和关键帧选择的*survival of the fittest*方法，“大量生成但挑选严格”



## 相关工作

1. Place Recognition：论文13比较了几种基于图像处理技术的位置识别方法。其中FAST特征检测和BRIEF描述子产生的二进制词袋可以通过DBoW2获得，与传统的SURF和SIFT相比计算时间小一个数量级。我们改进了DBoW2提供的词袋得到的ORB特征，具有旋转不变和尺度不变性。
2. Map Initialization
3. Monocular Sinultaneous Localization and Mapping



## 系统架构

1. 特征选择feature choice ：用于建图跟踪和地点识别（帧率重定位和回环检测）的特征是一样的。每张图片低于33ms，超过常用的SIFT，SURF等。由于要求旋转不变性，排除了BRIEF和LDB。

   - ORB，FAST角，256位描述子

2. 三个线程：tracking，local mapping，loop closing

   - tracking：用每帧定位相机并决定何时插入一个新的帧。先用之前的帧做初始特征匹配再用*motion-only* BA优化位姿。若tracking丢失，使用place recognition模块提供一个全局重定位。一旦有了一个初始的相机位姿和特征匹配的初始估计，将产生一个局部可视地图。这个局部地图使用系统维护的关键帧covisibility graph生成。

     接着，使用重投影搜索局部地图点匹配，并再次用这些匹配点优化相机位姿。最后，tracking线程将决定是否插入一个新关键帧。

   - local mapping：处理新关键帧，进行*local BA*，以得到一个给定相机位姿下优化后的周围场景重建。

     - *New correspondences for unmatched ORB in the new keyframe are searched in connected keyframes in the covisibility graph to triangulate new points* 为了三角化新点， 搜索covisibility graph中的相关帧，希望得到新帧中未匹配的ORB的新的响应。
     - 基于tracking线程收集的数据，筛选出高品质的点和非冗余关键帧。

   - loop closing：用新关键帧搜索loop（回环）

     - 检测到回环时，计算一个相似变换（similarity transformation）来说明回环中积累的drift。
     - 接着对齐回环两端并融合重复点
     - 最后执行一个服从相似约束（similarity constrain）的位姿图优化——Essential graph

   - 所有优化都将使用g2o库中的Levenberg-Marquardt算法

3. MapPoint和Keyframe的选择
   - 地图点$p_i$信息：
     1. 世界坐标系下的3D位置$X_{w,i}​$
     2. viewing direction  $n_i$，它的所有观察方向的平均单位向量。观察方向指的是连接该地图点和光心的射线方向；
     3. ORB描述子$D_i$，在所有能观察到该点的帧中具有最小hamming距离的描述子；
     4. 能观察到该点的最大和最小距离$d_{max}, d_{min}$，由ORB特征尺度不变性限制
   - 关键帧$K_i$信息：
     1. 相机位姿$T_{iw}$，将世界坐标系变换为相机坐标系的刚体变换；
     2. 相机内参（intrinsic），包括焦距和pricipal point
     3. 所有从该帧中提取的ORB特征，可能与一个地图点相关也可能不相关（?）；若提供畸变模型，特征的位置是无畸变的。
   - create generously, culling

4. Covisobility Graph & Essential gsraph

   - covisibility graph 一个无向有权图，以关键帧为节点，若两帧共享至少15个相同地图点的观测，则两节点间有边且权值为共有地图点数。
   - 使用位姿图优化（pose graph optimization）来纠正回环，将loop closing error分布在图中。
   - essential graph：包括一个生成树，covisibility graph边的子集，闭环边。从初始关键帧中逐渐建立一个生成树，得到一个covisibility graph的最小连通子图。当插入一个新的帧时，它将连接在共享最多观测的树节点上，删除时也将更新树。

5. 词袋

   - 描述子空间的离散化，由大量图片中得到的ORB描述子构建，作为数据库先验，逆向索引，查询效率高。
   - 由于关键帧有视觉重叠，查询树的响应往往不单一。orb-slam的处理方式是将在covisibility graph中相连的关键帧分组，并返回得分高于最高分的75%的虽有关键帧；

   

## 全自动图初始化

   - 二维场景：单应性 homography；非二维场景：基础矩阵（fundamental matrix）

   - 算法步骤

     1. Find initial correspondences：在当前帧$F_c​$中提取ORB特征，在参考帧$F_r​$中查找匹配$x_c\leftrightarrow x_r​$。若匹配数量不足，重置参考帧。

     2. Parallel computation of the two models：在两个平行线程中，使用标准DLT（直接线性变换）和八点法，分布计算单应矩阵$H_{cr}$和基础矩阵$F_{cr}$满足
        $$
        x_c = H_{cr}x_r,\ x_c^TF_{cr}x_r = 0
        $$
        为了两个线程处理的一致性，迭代次数、匹配点和个数都是相同的：基础矩阵使用八个点，其中4个点用于单应矩阵。在每次迭代时，计算模型M的分数$S_M$：
        $$
        S_M = \sum_i(\rho_M(d_{cr}^2(x_c^i,x_r^i,M))+\rho_M(d_{rc}^2(x_c^i,x_r^i,M)))
        $$

        $$
        \rho_M(d^2) = \left\{\begin{matrix}
        \Gamma -d^2,&d^2<T_M\\ 
        0,&d^2\geq T_M
        \end{matrix}\right.
        $$

        其中$d_{cr}^2​$$d_{rc}^2​$分别为从一帧到另外一帧的对称变换误差；$T_M​$为拒绝outliner的阈值，基于95%卡方检验决定（$T_H​$ = 5.99, $T_F = 3084​$）；$\Gamma​$数值上等于$T_H​$，则在两个模型inliner区域中，对于相同d的打分会相等。

     3. Model Selection：

        - 单应矩阵和基础矩阵各有优缺点；由于重建方法（reconstruction method）能够正确地从一个平面初始化或者它可以检测视差较小的情况并拒绝初始化，应该选择单应矩阵。另一方面，一个具有足够视差的非二维场景仅能用基础矩阵表达，虽然当某些匹配点处在同一平面或者有较小视差的时候，单应矩阵也能够描述它们。
        - 我们设定一个自适应阈值$R_H$来决定何时应该选择哪一个模型，当$R_H>0.40$时选择单应矩阵，因为此时已经捕捉到了足够的二维或小视差匹配。否则选择基础矩阵。

        $$
        R_H = \frac{S_H}{S_H+S_F}
        $$

        ​	

     4. Motion and structure from motion recovery

        选择了模型之后，我们就得到了运动状态的假设。

        - 在单应矩阵的情况下，我们使用*论文23的方法提取8个运动假设。这个假设通过测试来选择有效方案。如果在低视差下云点跑到相机的前面或者后面，测试容易因为选择了一个错误方案而无效。我们建议**直接三角化这八个方案，检查在两个相机前和较少重投影误差的情况下，是否存在一个在视差下有最多云点的方案。如果没有一个明确的最佳方案，我们放弃初始化并回到步骤1**。这个消除方案的机制使得低视差和双重模糊配置下的初始化变得鲁棒，被认为是我们方法鲁棒性的关键。

        - 在基础矩阵的情况下，我们使用标定矩阵将基础矩阵转换为一个本质矩阵：
          $$
          E_{rc} = K^TF_{rc}K
          $$
          并用论文[2]的单值分解方法提取4个运动假设。我们三角化着4个方案并像处理单应矩阵情况一样选择是否重新初始化。


     5. Bundle adjustment：最后我们通过全BA来优化初始化重构

​        

初始化流程如下：

```

```



## 追踪 tracking

tracking线程：处理来自相机的每一帧，优化相机位姿。

1. ORB 特征提取

   - 确定一幅图的角点数量：在8层金字塔提取FAST角点，尺度因子为1.2。对于图像分辨率重$512\times 384$到$752\times 480$，我们认为**1000**个角点是较为合适的。对于比这个范围高的分辨率，例如论文[14]中的KITTI数据集的分辨率为$1241\times 376$，我们提取2000个角点。为了确保角点均匀分布，我们将每个尺度层分成网格，每个网格提取至少5个角点。
   - 在每个网格检测角点。如果没有检测到足够的角点，检测器的阈值将自动调整。如果某些网格不存在角点（如缺乏纹理），单个网格的角点数量也会调整。
   - 计算FAST角点的orientation和ORB描述子。

2. 通过之前的帧初始化位姿估计

   - 若对上一帧的追踪成功，我们使用一个**匀速运动模型**来预测相机位，搜索上一帧观测到的地图点云。若没有足够的匹配，我们加大搜索范围搜索上一帧地图云点附近的点。通过寻找到的对应关系优化相机位姿。

3. 通过全局重定位初始化位姿估计

   - 若追踪丢失，我们把当前帧转换为词袋，查询识别数据库得到全局重定位的候选帧。计算ORB特征和每个关键帧中的地图云点的对应关系。对每个关键帧执行RANSAC迭代计算，用PnP算法找相机位姿。如果有足够的inliers确定相机位姿，我们优化该位姿并在候选帧的地图点云中搜索更多匹配，再一次优化位姿。如果再次地，有足够的inliers，继续追踪过程。

4. 追踪局部地图

   一旦有了一个相机位姿估计和特征匹配的初始集，我们就可以将地图投影到帧中并搜索更多地图点对应关系。为了限制大型地图的复杂度，只投影局部地图。这个局部地图包含了关键帧集$K_1$$K_2$$K_{ref}$。$K_1$是与当前帧有共同地图云点的关键帧组成的集合，$K_2$是在covisibility graph中与$K_1$相邻的关键帧组成的集合，$K_{ref}$是$K_1$的子集，由与当前帧有最多的共享云点的关键帧组成。

   搜索每个当前帧中，$K_1$$K_2$能“看到”的云点算法如下：

   1. 计算当前帧中地图云点投影x。如果超出范围则丢弃该点。
   2. 计算当前观察方向v和地图点平均观察方向n。如果$v\cdot n<cos60^{\c}$则丢弃该点。
   3. 计算地图云点到相机中心的距离$d$。如果$d\notin [d_{min},d_{max}]$，即它不在云点尺度不变区间，则丢弃该点。
   4. 计算每帧图像的尺度因子，$d/d{min}$
   5. 对比地图云点的特征描述子D和当前帧红还未匹配的ORB特征，在预测尺度，临近x和相关地图云点中做最佳匹配。

5. 新关键帧的判断标准

   最后一步是，确定当前帧是否可以作为关键帧。在（下一步）局部建图中有筛选冗余关键帧的机制。这一步的要求是尽可能快地插入新帧，这可以使得tracking thread对相机运动的计算（尤其是旋转）更具有鲁棒性。

   插入一个新关键需要满足如下要求：

   1. 距离上一次全局重定位至少20帧
   2. 局部建图线程处于空闲状态，或者距离上一次插入关键至少20帧；如果需要关键帧插入（过了20帧）而LocalMapping线程忙，则发送信号给LocalMapping线程，停止局部地图优化，使得新的关键帧可以被及时处理（20帧，大概过去了不到1s）
   3. 当前帧追踪至少50个点。确保了跟踪定位的精确度
   4. 当前帧追踪到参考关键帧的地图点数量少于90%。确保关键帧之间有明显的视觉变化。



## 局部建图

local mapping线程处理每个新关键帧$K_i$

1. 插入关键帧

   - 更新covisibility graph，添加一个新的节点表示$K_i$，更新边（连接$K_i$节点和共享地图点的其他关键帧）。
   - 更新生成树，将$K_i$连接到有最多共有点的帧的节点上。
   - 计算代表$K_i$帧的词袋（帮助三角化新点的数据关联）

2. 最近地图云点筛选

   为了将点保存在地图中，最初三个关键帧创建之后，地图点需要经过一个严格的测试以保证它们可被跟踪且正确三角化了。要求：

   1. 跟踪必须找到在多于25%的帧中找到这个点；说明这个点可以视作可见的。
   2. 如果多于一个关键帧被地图云点创建传递过来

3. 创建新地图云点

4. 局部Bundle Adjustment

5. 局部关键帧筛选

## 回环检测

loop closing线程处理local mapping线程处理的最后一个关键帧，并检测回环。



![5610568-fcc78bf37a5cba72](C:\Users\Yuki\Desktop\5610568-fcc78bf37a5cba72.webp)

![5610568-fade6ce4eeb0b4ef](C:\Users\Yuki\Desktop\5610568-fade6ce4eeb0b4ef.webp)

![5610568-a51c8655f0ddc03f](C:\Users\Yuki\Desktop\5610568-a51c8655f0ddc03f.webp)