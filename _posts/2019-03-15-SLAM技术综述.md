---
title: SLAM技术综述
date: 2019-03-15 20:00:00
categories:
- SLAM
tag:
- slam-notes
---


实训 is coming.... 








### 综述

1. SLAM技术综述

   - 定位，建图，导航，探索

   - 假设已经有地图：定位和导航（路径规划），不需要探索。在移动机器中，考虑如何建立地图，同时进行定位和建图。

   - 如何用SLAM技术进行定位和建图？

   - 通用框架

     - 流程 框架和算法固定

       ![D4TLg.jpg](https://ww1.yunjiexi.club/2019/03/21/D4TLg.jpg)

     - 前端：传感器数据进入系统进行前端数据：粗略的位置和地图表示，根据传感器不同有不同的算法；

       - 视觉SLAM（相机）   前端 ==视觉里程计== CV+测量几何
       - 激光SLAM

     - 后端：处理前端传来的粗略数据

       - 早期：卡尔曼滤波器及其扩展
       - 最近主流：==非线性优化== 光速法平差

     - 回环检测：检测什么时候回到原点，减少累计误差

     - 建图：根据估计得到的相机轨迹和地图得到更加精确的地图

2. 激光SlAM

   - 激光传感器：SLAM matching （激光点匹配）*sebastian thrun*
   - 早期是激光定位问题（概率机器人学），大多数是rose提供的算法，算法实现本身研究少
   - 2000往后一直是建立高精度地图而不是建立更像人类认知的拓扑地图
   - 方式和产业已经比较成熟，做开题文章比较难，但是在室内做类似动物的导航的避障探索（可以做），现有方法是全局和局部耦合，如何利用激光数据进行训练，使得可以在多障地形中导航
   - 如何在嵌入式arm方面（计算资源少）去做？可以选择精度比较高的传感器；计算资源消耗的多少与particle（粒子数）相关，建图（15~25）比，激光越精确，用到的粒子数更少；因为往往需要很多粒子数的做比较精确的估计，减少出现回环错误的概率；
   - 现有的扫地机器人的地图构建精度不高
   - gmapping：占据栅格图所用的建图方法

3. ==视觉SLAM==

   - 主要区别：根据图像估计相机运动

     1. 相机运动一般是3d运动，需要精确描述相机在三维空间的位置，需要大量矩阵知识（旋转矩阵）
     2. 如何根据图像之间的差异将运动估计出来：纷争特征点法和直接法两类

   - 主流相机：根据是否提供深度信息的不同，视觉里程计算法不同；

     ![D4ZNe.jpg](https://ww1.yunjiexi.club/2019/03/21/D4ZNe.jpg)

     1. 单目相机：单帧照片估计；一开始的问题是通过照片和照片之间的比对确定相机的运功（2d到2d），通过分解essential矩阵/fundamental矩阵/homographic矩阵 估计，存在尺度不确定问题（主要原因是如果将地图和轨迹同时放大和缩小结果时不变的）
     2. 双目相机：有深度图给出深度信息难度降低，没有尺度不确定问题：通过左右眼视差估计距离，特别是要计算每一个像素的距离的时候计算机的计算量非常大
     3. 深度RGBD相机：有深度图给出深度信息，没有尺度不确定问题：通过投射光并测量返回光的时间和pattern来物理估计

   - **视觉里程计的两种方法：**

     - 基于==特征点==（主流）：orb-slam 
       - 通过特征提取和特征匹配抓取一组匹配点并得到匹配点的空间关系来估计相机运动（不管用哪一种相机的数据）
       - 缺点：特征点在空间经常过于集中（纹理信息丰富，像素变化明显区域），在稀疏；在梯度变化不明晰的地方容易特征确实（白墙等）；计算量也非常大，仅能在pc端正常运行；
     - 基于==直接法==（近年）：以svo和lsd为代表，从光流发展而来；
       - 根据图像像素变化估计：假设同一个像素在不同视角下灰度是一样的，主要是构建一个最小化光度误差的优化问题并求解
       - 分类（使用像素的多少）：稠密（整幅图像），半稠密（使用像素梯度明显的地方），稀疏（关键点：像素变化明显的角点或者边缘）
       - 优点：节省特征描述的计算，弥补特征丢失的问题
       - 代表性工作：dbo lsd dso svo，目前稀疏直接法速度最快：svo2.0（代码未开源）论文中提出能够在pa（？）上达到200赫兹的速度甚至更快；dso也可以达到120左右特征点法不能做到

   - 视觉里程计使用的是相邻帧图像的运动信息，累计误差不可避免。希望得到一致的轨迹就需要后端优化和回环检测

4. 后端优化

   - EKF（已抛弃）
   - 非线性优化

5. 回环检测

   - 测量误差默认高斯分布，构建一个最小二乘问题通过非线性优化求解
   - 在视觉SLAM中更有效（因为图像信息位置比对信息更丰富）
   - 词袋？bag of word 视觉回环检测最主流，在前端中也可用于加速匹配

6. 空间认知

   - 输入1为自身的运动估计（rotation，self-motion等），输入2为visial input（眼睛捕获环境图像）

   - 传感器组合？

     ![D4hdp.jpg](https://ww1.yunjiexi.club/2019/03/21/D4hdp.jpg)

7. SLAM学习经验，技术难点，应用场景

Q&A

- 标定过的单目SLAM还存在尺度不确定的问题吗？

  > 存在，标定只是内参，不光有尺度不确定性，还会有尺度漂移



### 思路

*\*：已知集成在OpenCV*

视觉里程计：特征点法 ORB

1. 提取Oriented FAST特征点，计算BRIEF描述子，快速近似最近邻（FLANN）匹配算法*
2. 匹配好的特征点+对极约束=>恢复两帧之间相机运动
3. 用相机运动估计特征点的空间位置，单目SLAM中通过三角测量来恢复深度信息
4. 求解PnP问题，根据n个3D空间点以及他们的投影位置估计相机位姿。（单目需要先初始化）；解法：DLT,EPnP，UPnP，Bundle Adjustment
5. 求解3D-3D的位姿估计：ICP（？）解法：SVD，Bundle Adjustment



视觉里程计：直接法



## References

- [半闲居士博客园](https://www.cnblogs.com/gaoxiang12/p/3695962.html)
- 《视觉SLAM十四讲》[BLBL公开课](https://www.bilibili.com/video/av19397094?from=search&seid=9220779439046733623)   [Github代码](https://github.com/gaoxiang12/slambook)
- 单目视觉
  - 《基于单目视觉的同时定位与地图构建方法综述_刘浩敏》
  - 《基于特征点提取的单目视觉里程计的研究_吕强》
  - 《基于光流法的单目视觉里程计研究_郑驰》





SLAM